{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "Uu0Zt6GnrXBI",
        "outputId": "73de7e7e-0364-4878-f6f0-6007ca062224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5e20a5d485d4e89651.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5e20a5d485d4e89651.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "!pip install transformers gradio torch --quiet\n",
        "\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# Load a lightweight GPT-2 model (DistilGPT-2 is faster)\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "# Function to generate text\n",
        "def generate_text(prompt):\n",
        "    result = generator(prompt, max_length=50, num_return_sequences=1)\n",
        "    return result[0]['generated_text']\n",
        "\n",
        "# Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_text,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Fast Text Generator\",\n",
        "    description=\"Enter a prompt and see quick text generation.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai gradio requests --quiet\n",
        "\n",
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "import requests\n",
        "\n",
        "# ðŸ”¹ Set your API Keys (Replace with your actual keys)\n",
        "GEMINI_API_KEY = \"AIzaSyDnMG3av2_FdnX8oD6l7Zfd_SMAK2PwGVw\"\n",
        "GOOGLE_CSE_API_KEY = \"AIzaSyBnDeCvfQum-j017AdFip_VNyZHt6AQ-gM\"\n",
        "GOOGLE_CSE_ID = \"30a5a426119f14634\"\n",
        "\n",
        "# ðŸ”¹ Configure Gemini\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "gemini_model = genai.GenerativeModel(\"gemini-pro\")\n",
        "\n",
        "# ðŸ”¹ Function to refine search query using Gemini\n",
        "def refine_search_query(user_input):\n",
        "    response = gemini_model.generate_content(f\"Convert this into a precise image search query: {user_input}\")\n",
        "    return response.text.strip()\n",
        "\n",
        "# ðŸ”¹ Function to search images using Google Custom Search API\n",
        "def search_images(query):\n",
        "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"cx\": GOOGLE_CSE_ID,\n",
        "        \"key\": GOOGLE_CSE_API_KEY,\n",
        "        \"searchType\": \"image\",\n",
        "        \"num\": 5\n",
        "    }\n",
        "    response = requests.get(url, params=params).json()\n",
        "\n",
        "    # Extract image URLs\n",
        "    image_urls = [item[\"link\"] for item in response.get(\"items\", [])]\n",
        "    return image_urls\n",
        "\n",
        "# ðŸ”¹ Final function for Gradio\n",
        "def image_search(prompt):\n",
        "    refined_query = refine_search_query(prompt)\n",
        "    return search_images(refined_query)\n",
        "\n",
        "# ðŸ”¹ Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=image_search,\n",
        "    inputs=\"text\",\n",
        "    outputs=gr.Gallery(label=\"Search Results\"),\n",
        "    title=\"AI-Powered Image Search with Gemini\",\n",
        "    description=\"Enter a query, and AI will find the best images for you!\"\n",
        ")\n",
        "\n",
        "# ðŸ”¹ Launch Gradio app\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "7QFVq4IR8L28",
        "outputId": "5ff19960-47ac-4b93-bba4-853051811e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c91c5bca3f5b363212.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c91c5bca3f5b363212.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai gradio --quiet\n",
        "\n",
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "\n",
        "# ðŸ”¹ Set your Gemini API Key (Replace with your actual key)\n",
        "GEMINI_API_KEY = \"AIzaSyDnMG3av2_FdnX8oD6l7Zfd_SMAK2PwGVw\"\n",
        "\n",
        "# ðŸ”¹ Configure Gemini\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "gemini_model = genai.GenerativeModel(\"gemini-pro\")  # Using the free version\n",
        "\n",
        "# ðŸ”¹ Function to generate chatbot responses\n",
        "def chatbot_response(user_input):\n",
        "    response = gemini_model.generate_content(user_input)\n",
        "    return response.text  # Return the AI-generated reply\n",
        "\n",
        "# ðŸ”¹ Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_response,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Gemini AI Chatbot\",\n",
        "    description=\"Chat with Google's Gemini AI for free!\"\n",
        ")\n",
        "\n",
        "# ðŸ”¹ Launch chatbot\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "gJWFy5HX_6VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai gradio --quiet\n",
        "\n",
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "\n",
        "# ðŸ”¹ Set up API Key (Replace 'YOUR_API_KEY' with your actual API key)\n",
        "genai.configure(api_key=\"AIzaSyDnMG3av2_FdnX8oD6l7Zfd_SMAK2PwGVw\")\n",
        "\n",
        "# ðŸ”¹ Use the free version of Gemini\n",
        "model = genai.GenerativeModel(\"gemini-pro\")  # \"gemini-pro-latest\" can also be used\n",
        "\n",
        "# ðŸ”¹ Function to generate text (with token limit for speed)\n",
        "def generate_text(prompt):\n",
        "    try:\n",
        "        response = model.generate_content(prompt, generation_config={\"max_output_tokens\": 50})\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# ðŸ”¹ Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_text,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Free Gemini AI Text Generator\",\n",
        "    description=\"Enter a prompt and get AI-generated text using the free Gemini API.\"\n",
        ")\n",
        "\n",
        "# ðŸ”¹ Launch Gradio app\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "Xkfp9q5Bxxpw",
        "outputId": "ef05bb50-b7f8-49b0-e67c-de9197f870c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://040b7dd3318bc39b7d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://040b7dd3318bc39b7d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}